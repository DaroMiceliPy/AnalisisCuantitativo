# -*- coding: utf-8 -*-
"""PCA para analisis exploratorio en iris dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1StJpP11v7SAIcc0TTMJyZzvdWdYkai2u
"""

import pandas as pd
import matplotlib.pyplot as plp
import numpy as np
import seaborn as sbn
from sklearn.decomposition import PCA
''' Ahora vamos a usar un algoritmo de aprendizaje no supervisado 
para analisis exploratorio. Vamos a usar PCA para reduccion de dimensiones '''


iris = sbn.load_dataset("iris")

iris.info()
iris

sbn.pairplot(iris, hue = "species") #Con este tipo de grafico vemos las relaciones entre las distintas variables

model = PCA(n_components = 2) #Le pedimos que el modelo tenga 2 componentes que permita ver las relaciones entre las caracteristicas

X = iris.drop(["species"], axis = 1).to_numpy()

model.fit(X)
X_2D = model.transform(X)

iris["PCA1"] = X_2D[:, 0]
iris["PCA2"] = X_2D[:, 1]
sbn.lmplot("PCA1", "PCA2", data = iris, hue = "species", fit_reg = False)

'''Vemos que en dos dimensiones las species estan bien diferenciadas y separadas. Esto significa que un modelo
de clasificador relativamente sencillo podra ser efectivo para este dataset '''
model.explained_variance_ratio_ #Con esto vemos la varianza explicada de cada componente

with plp.style.context("dark_background"):
  plp.plot([1, 2], model.explained_variance_ratio_, "-o", label = "Varianza explicada de cada componente")
  plp.plot([1, 2], np.cumsum(model.explained_variance_ratio_), "-*", label = "Varianza explicada acumulada")
  plp.xlim(0, 7)
  plp.ylim(0, 1.05)
  plp.legend(loc=5)